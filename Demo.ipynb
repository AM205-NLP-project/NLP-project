{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f368db6-0e22-447e-83a7-792d1c597458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f3618d1-35c8-436f-a038-17b31fad8cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ['train', 'val', 'test']\n",
    "data = {\n",
    "    k: json.load(open(f'tune/words_dataset_unique.csv_{k}.json'))\n",
    "    for k in splits\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1718747-4ab8-49fa-b90f-02cf24e2e206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload models\n",
    "modelf = GPT2LMHeadModel.from_pretrained('tune/model_unique_best/')\n",
    "modelr = GPT2LMHeadModel.from_pretrained('tune/model_unique_rev_best/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b4a324-ca8a-44fd-8a4d-c7de09c34df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get tokenizer\n",
    "tok = AutoTokenizer.from_pretrained('gpt2')\n",
    "tok.add_special_tokens({'pad_token': '<|endoftext|>'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0575a9b-5cac-40c0-80e2-cd844eb50e2d",
   "metadata": {},
   "source": [
    "## Word Guessing Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19e91f80-bcc5-4648-b4ac-6c9f3396c3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_words(query, target, n_words, maxlen=8, verbose=False):\n",
    "    seed_txt = 'Definition: ' + query + ' ; Word:'\n",
    "\n",
    "    input_ids = tok.encode(seed_txt, return_tensors='pt')\n",
    "\n",
    "    beam_outputs = modelr.generate(\n",
    "        input_ids,\n",
    "        max_length=input_ids.shape[1] + maxlen,\n",
    "        num_beams=n_words,\n",
    "        num_return_sequences=n_words,\n",
    "        early_stopping=True,\n",
    "        pad_token_id=tok.eos_token_id,\n",
    "    )\n",
    "\n",
    "    words = []\n",
    "    if verbose:\n",
    "        print('Seed:', seed_txt)\n",
    "        print(f\"Guesses (True Answer: {target}):\\n\" + 100 * '-')\n",
    "\n",
    "    for i, beam_output in enumerate(beam_outputs):\n",
    "        w = tok.decode(beam_output, skip_special_tokens=True).replace(seed_txt, '').strip()\n",
    "        words.append(w)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"{}: {}\".format(i, w))\n",
    "\n",
    "    metrics = {\n",
    "        'Exact MRR': max([1 / (ix + 1) if w == target else 0 for ix, w in enumerate(words)]),\n",
    "    }\n",
    "    \n",
    "    if verbose:\n",
    "        print('-' * 100)\n",
    "        for k, v in metrics.items():\n",
    "            print(f'{k}: {v:.2f}')\n",
    "    \n",
    "    return words, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e383dc87-7069-4d1c-9f7e-7f7bcd6b21fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: Definition: A large mammal found in arctic regions ; Word:\n",
      "Guesses (True Answer: polar bear):\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: polar bear\n",
      "1: penguin\n",
      "2: bear\n",
      "3: grizzly\n",
      "4: fox\n",
      "5: mammoth\n",
      "6: iceman\n",
      "7: raccoon\n",
      "8: puffer\n",
      "9: stag\n",
      "10: skunk\n",
      "11: wolf\n",
      "12: skank\n",
      "13: deer\n",
      "14: pack\n",
      "15: polaroid\n",
      "16: panda\n",
      "17: siren\n",
      "18: bosh\n",
      "19: tule\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exact MRR: 1.00\n"
     ]
    }
   ],
   "source": [
    "# d = 'To rapidly move. Do this in a race'\n",
    "# w = 'run'\n",
    "# n = 10\n",
    "\n",
    "# d = 'A plant with petals'\n",
    "# w = 'flower'\n",
    "# n = 20\n",
    "\n",
    "# d = 'A device to control a television'\n",
    "# w = 'remote'\n",
    "# n = 10\n",
    "\n",
    "# d = 'The use of computing to solve scientific and engineering problems, especially by means of simulation, or the construction of mathematical models of physical, chemical or biological processes'\n",
    "# w = 'scientific computing'\n",
    "# n = 100\n",
    "\n",
    "# d = '(mathematics) The study of algorithms to solve mathematical problems concerning continuous sets of values (such as the real numbers, complex numbers or vector spaces).'\n",
    "# d = 'the study of algorithms for the problems of continuous mathematics'\n",
    "# w = 'numerical analysis'\n",
    "# n = 100\n",
    "\n",
    "# d = 'a simple hydrocarbon; a powerful greenhouse gas.'\n",
    "# d = 'a poweful greenhouse gas'\n",
    "# d = 'colourless, odourless gas that occurs abundantly in nature and as a product of certain human activities'\n",
    "# w = 'methane'\n",
    "# n = 100\n",
    "\n",
    "# d = '(physics) In the Standard Model, an elementary subatomic particle that forms matter. They combine to form hadrons, such as protons and neutrons.'\n",
    "# w = 'quark'\n",
    "# n = 100\n",
    "\n",
    "d = 'A large mammal found in arctic regions'\n",
    "w = 'polar bear'\n",
    "n = 20\n",
    "\n",
    "_ = guess_words(d, w, n, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1df9de-37d8-45e0-80ae-f077ce4d8859",
   "metadata": {},
   "source": [
    "## Definition Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c4e1c83c-b36d-4ba6-acb8-378851201652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_p_sample(text, p, temp=1.0, maxlen=128, minlen=2, num_samples=3, verbose=True, latex=False, label=None):\n",
    "    prefix = torch.tensor(tok.encode(text)).unsqueeze(0)\n",
    "\n",
    "    sample_outputs = modelf.generate(\n",
    "        prefix,\n",
    "        pad_token_id=50256,\n",
    "        do_sample=True,\n",
    "        temperature=temp,\n",
    "        max_length=prefix.shape[1] + maxlen,\n",
    "        min_length=prefix.shape[1] + minlen,\n",
    "        top_p=p,\n",
    "        num_return_sequences=num_samples,\n",
    "    )\n",
    "\n",
    "    samples = []\n",
    "    for i, sample_output in enumerate(sample_outputs):\n",
    "        ox = tok.decode(sample_output, skip_special_tokens=True)\n",
    "        samples.append(ox)\n",
    "\n",
    "        if verbose:\n",
    "            out = \"{}: {}\".format(i, ox)\n",
    "            print(out)\n",
    "        \n",
    "        if latex:\n",
    "            if i == 0:\n",
    "                out = text if label is None else label\n",
    "            else:\n",
    "                out = ''\n",
    "            out += ' & \\\\parbox{10cm}{'\n",
    "            out += ox.replace(text, '')\n",
    "            out += '} \\\\\\\\'\n",
    "            print(out)\n",
    "            print('\\\\hline')\n",
    "    \n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b03c1133-4f00-470b-a212-d12ca60d6bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Word: polar bear ; Definition: polar bear (plural polar bears)\n",
      "1: Word: polar bear ; Definition: (figuratively) Anything similar, similar to (or similar to) a polar bear, such as a polar bear in fur or feathers; an attractive or intimidating looking person, person, or person-animal.\n",
      "2: Word: polar bear ; Definition: (uncountable, derogatory) A large mammal of similar weight, stature and sexual orientation.\n"
     ]
    }
   ],
   "source": [
    "p = 0.95\n",
    "# w = 'eigenspectrum'\n",
    "# w = 'matrix'\n",
    "# w = 'scientific computing'\n",
    "# w = 'tweet'\n",
    "# w = 'jawn'\n",
    "# w = 'polar bear'\n",
    "\n",
    "tx = 'Word: ' + w + ' ; Definition:'\n",
    "_ = top_p_sample(tx, p, label=w, verbose=True, latex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd174fc-81f1-442c-99c5-c14858369ea5",
   "metadata": {},
   "source": [
    "## Example Usage Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f2827d9d-8623-4046-bed4-feee079ea286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Word: polar bear ; Example: That's an image of polar bears all over, one of the polar bears looking down towards their captions as they travel through the air in a circular motion.\n",
      "1: Word: polar bear ; Example: The polar bear is the smallest of the polar bears, but is larger than many a mammal.\n",
      "2: Word: polar bear ; Example: Polar bears are typically seen in many different species, including polar bears in the Australian and New Zealand polar bear subspecies.\n"
     ]
    }
   ],
   "source": [
    "p = 0.95\n",
    "# w = 'scientific computing'\n",
    "# w = 'matrix'\n",
    "# w = 'tweet'\n",
    "# w = 'eigenspectrum'\n",
    "# w = 'jawn'\n",
    "w = 'polar bear'\n",
    "\n",
    "tx = 'Word: ' + w + ' ; Example:'\n",
    "_ = top_p_sample(tx, p, label=w, verbose=True, latex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805ab63a-3fec-43aa-9351-e23bd35d7e36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
